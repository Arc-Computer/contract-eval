# Configuration for Contract Generation Evaluation

# Inference mode: "api" for GPU server, "local" for local execution, "hybrid" for API with local fallback
inference_mode: "api"

inference_api:
  endpoint: "http://localhost:8000"  # FastAPI server on same machine
  api_key: ""  # No auth needed for localhost
  timeout: 600  # Increased to 10 minutes for large generations
  max_retries: 3

api_keys:
  openai: "YOUR_OPENAI_API_KEY"
  anthropic: "YOUR_ANTHROPIC_API_KEY"
  google: "YOUR_GOOGLE_API_KEY"
  together: "YOUR_TOGETHER_API_KEY"  # Only used if inference_mode is "local" for student

models:
  teacher:
    repo_id: "aman-jaglan/et-8b"
    device: "cuda"
    max_new_tokens: 500  # Reduced for testing
    temperature: 0.7
    
  student:
    model_name: "Qwen/Qwen3-8B"
    provider: "together"  # or "huggingface"
    max_new_tokens: 1000  # Reduced for testing
    temperature: 0.3
    
  baselines:
    gpt5:
      model: "gpt-5"  # GPT-5 released August 2025, using main reasoning model
      temperature: 0.3
      max_tokens: 1000  # Reduced for testing
    claude:
      model: "claude-opus-4-1-20250805"  # Claude Opus 4.1 released August 5, 2025
      temperature: 0.3
      max_tokens: 1000  # Reduced for testing
      
  judge:
    model: "gemini-2.5-pro"  # Gemini 2.5 Pro stable version with thinking capabilities
    temperature: 0.1
    
dataset:
  repo_id: "Jarrodbarnes/rcl-specialized-teacher-enterprise"
  split: "train"
  num_examples: 99  # Using last 99 examples (500-599) not used in SFT training
  
evaluation:
  checkpoint_interval: 10
  save_intermediate: true
  batch_size: 1
  timeout_seconds: 60
  max_retries: 3
  
paths:
  results_dir: "./results"
  checkpoints_dir: "./results/checkpoints"
  final_report: "./results/final_report.json"
  logs_dir: "./logs"